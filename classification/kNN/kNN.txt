K- 최근접 이웃 모델 (k - Nearest Neighbors, kNN)

비회귀분석 모델 중 하나로 간단하고 사용하기 쉽다.
특정 레코드를 분류하려는  경우에 유사한 다른 레코드를 고려해야 한다는 기본 전제를 따른다.

github.com/sjwhitworth/golearn
github.com/rikonor/go-ann
github.com/akreal/knn

A,B 두 클래스가 있고, x1,x2 두 수치를 기반으로 분류한다고 가정
이제 알려지지 않은 클래스가 있는 새로운 데이터요소가 있다고 가정

이 새로운 데이터 요소는 공간의 어딘가에 자리를 잡을 것이고 kNN을 기반으로 이 새로운 요소를 분류하기 위해서는
다음 내용을 수행해야 한다..

1. 가까운 정도를 측정한 결과를 기반으로 새로운 지점에 대한 k 최근접 지점을 찾는다

2. 클래스 A에 포함된 k최근접 지점의 수가 얼마인지와 클래스 B에 포함된  k 최근접 지점의 수가 얼마인지 확인한다..

3. 새로운 지점을 k최근접 이웃을 더 많이 가지고 있는 그룹으로 분류한다.




   kNN을 결정하는 데 사용할 수 있는 다양한 유사도 측정방법

일반적인 방법 : 유클리드 거리 측정법
유클리드 거리 측정법 : 데이터 수치들로 구성되는 공간의 한 요소에서 다른 요소로의 직선거리를 측정한다..
다른 방법 : 맨하탄 거리 특정법, 민코스키 거리 측정법, 코사인 유사도 측정법, 자카드 유사도 측정법


kNN의 가정 및 문제점
kNN은 단순함으로 인해 너무 많은 가정은 하지 않는다..그러나 사용할 때 주의해야 할 몇 가지 일반적인 문제점들이 있다.

1. kNN은 게으른 알고리즘. 즉 , 예측을 수행하기 저에 훈련 또는 적합과 같은 과정을 진행하지 않고 예측을 해야할 때 거리나 유사도를 계산해야한다. 
따라서 데이터가 많은 경우 계산 및 요소를 검색하는 속도가 매우 느려질 수 있다.

2. k를 선택하는 과정에서 형식을 부여하고 선택한 k에 정당성을 제공해야한다. k를 선택하는 일반적인 방법은 k값의 범위를 기반으로 검색하는 것이다..

3. kNN은 다른 수치보다 어떤 수치가 더 중요한지에 대해 고려하지 않는다.


